import{_ as l,C as t,c as p,o as c,j as n,G as a,a4 as o,a as u}from"./chunks/framework.B23BjOVS.js";const v=JSON.parse('{"title":"Why I Built Lynq: From Internal Tool to Open Source ðŸ‘¶","description":"The journey of building Lynq - from solving internal provisioning challenges to discovering a new paradigm called Infrastructure as Data.","frontmatter":{"title":"Why I Built Lynq: From Internal Tool to Open Source ðŸ‘¶","date":"2025-12-17T00:00:00.000Z","author":"Tim Kang","github":"selenehyun","description":"The journey of building Lynq - from solving internal provisioning challenges to discovering a new paradigm called Infrastructure as Data.","tags":["Lynq","Open Source","Infrastructure as Data","RecordOps"],"sidebar":false,"editLink":false,"prev":false,"next":false},"headers":[],"relativePath":"blog/why-i-built-lynq.md","filePath":"blog/why-i-built-lynq.md","lastUpdated":1766025659000}'),d={name:"blog/why-i-built-lynq.md"};function h(m,e,g,y,b,f){const s=t("BlogPostMeta"),r=t("RolloutAnimation"),i=t("BlogPostFooter");return c(),p("div",null,[e[0]||(e[0]=n("h1",{id:"why-i-built-lynq-from-internal-tool-to-open-source-ðŸ‘¶",tabindex:"-1"},[u("Why I Built Lynq: From Internal Tool to Open Source ðŸ‘¶ "),n("a",{class:"header-anchor",href:"#why-i-built-lynq-from-internal-tool-to-open-source-ðŸ‘¶","aria-label":'Permalink to "Why I Built Lynq: From Internal Tool to Open Source ðŸ‘¶"'},"â€‹")],-1)),a(s),e[1]||(e[1]=o(`<p>What started as a solution to my own Terraform scaling pains became an open source project exploring a different approach to infrastructure management.</p><p>This post shares the journey from building an internal &quot;Tenant Operator&quot; to discovering what I now call Infrastructure as Data, including a thought-provoking conversation with Ansible creator Michael DeHaan about the complexity trap in modern infrastructure.</p><h2 id="the-beginning-hitting-terraform-s-limits" tabindex="-1">The Beginning: Hitting Terraform&#39;s Limits <a class="header-anchor" href="#the-beginning-hitting-terraform-s-limits" aria-label="Permalink to &quot;The Beginning: Hitting Terraform&#39;s Limits&quot;">â€‹</a></h2><p>In 2023, I was running a SaaS platform and handling per-customer Kubernetes resource provisioning. Deployment, Service, Ingress, ConfigMap... each customer needed almost identical resource structures, with only the customer ID and a few config values being different.</p><p>At first, I solved it with Terraform. I abstracted everything cleanly into modules and managed per-customer resources. My customers were business owners, so they could wait a bit for provisioning, and it worked fine for a while.</p><p>But as the customer count grew, problems started to show. The time to sync Terraform state and provision resources kept increasing proportionally with the number of customers. Eventually, I&#39;d run <code>terraform apply</code>, go do something else, and come back much later to review the plan and apply it.</p><div class="language-bash line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># This flow repeated every time</span></span>
<span class="line"><span style="color:#B392F0;">terraform</span><span style="color:#9ECBFF;"> plan</span><span style="color:#79B8FF;"> -out=tfplan</span><span style="color:#6A737D;">  # ... wait 10 minutes</span></span>
<span class="line"><span style="color:#6A737D;"># (go do something else, come back)</span></span>
<span class="line"><span style="color:#B392F0;">terraform</span><span style="color:#9ECBFF;"> apply</span><span style="color:#9ECBFF;"> tfplan</span><span style="color:#6A737D;">      # ... wait again</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>It was stable and not bad. But isn&#39;t reducing these small, repetitive tasks what engineers do best?</p><p>&quot;The customer data is already in the database. Why do I have to sync it manually every time?&quot;</p><p>That question was the beginning of Lynq.</p><h2 id="the-birth-of-tenant-operator" tabindex="-1">The Birth of Tenant Operator <a class="header-anchor" href="#the-birth-of-tenant-operator" aria-label="Permalink to &quot;The Birth of Tenant Operator&quot;">â€‹</a></h2><p>I decided to build a Kubernetes Operator. I named it &quot;Tenant Operator&quot; because the goal at the time was to solve multi-tenant SaaS customer provisioning.</p><p>The first version was simple:</p><ol><li>Periodically query the MySQL database for active customers</li><li>Create Kubernetes resources for each customer using predefined templates</li><li>Automatically clean up resources for deactivated customers</li></ol><div class="language-yaml line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">yaml</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># Early TenantRegistry (now LynqHub)</span></span>
<span class="line"><span style="color:#85E89D;">apiVersion</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">kubernetes-tenants.org/v1</span></span>
<span class="line"><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">TenantRegistry</span></span>
<span class="line"><span style="color:#85E89D;">spec</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#85E89D;">  source</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#85E89D;">    mysql</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#85E89D;">      query</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">&quot;SELECT id, domain, plan FROM customers WHERE active = 1&quot;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>After a few weeks of development, the first version was complete, and over 200 customer resources started syncing automatically. When a new customer signed up, all resources were created within seconds. When a contract expired, I just set <code>is_active</code> to <code>false</code> in the database and resources were cleaned up automatically. No more waiting for <code>terraform apply</code>.</p><h2 id="could-this-be-used-elsewhere" tabindex="-1">&quot;Could This Be Used Elsewhere?&quot; <a class="header-anchor" href="#could-this-be-used-elsewhere" aria-label="Permalink to &quot;&quot;Could This Be Used Elsewhere?&quot;&quot;">â€‹</a></h2><p>While using Tenant Operator, I realized this wasn&#39;t just a tool for tenant provisioning. The core pattern was simple: <strong>&quot;Automatically provision Kubernetes resources based on data from somewhere&quot;</strong></p><p>That&#39;s when I decided to open source it. This seemed like a problem others were facing too, not just me.</p><h2 id="refactoring-for-general-use" tabindex="-1">Refactoring for General Use <a class="header-anchor" href="#refactoring-for-general-use" aria-label="Permalink to &quot;Refactoring for General Use&quot;">â€‹</a></h2><p>After deciding to open source, the first thing I did was make the interface more generic. We were using MySQL, so Tenant Operator only supported MySQL, but I redesigned the datasource interface to accommodate popular databases like PostgreSQL.</p><p>The domain-specific terms like &quot;tenant&quot; and &quot;customer&quot; were replaced with more abstract concepts:</p><table tabindex="0"><thead><tr><th>Before</th><th>After</th></tr></thead><tbody><tr><td>TenantRegistry</td><td>LynqHub</td></tr><tr><td>TenantTemplate</td><td>LynqForm</td></tr><tr><td>Tenant</td><td>LynqNode</td></tr><tr><td>customer_id</td><td>uid</td></tr><tr><td>domain</td><td>(generalized via extraValueMappings)</td></tr></tbody></table><p>I started collecting use cases. Beyond the big picture, small ideas came to mind:</p><ul><li>Syncing DB data to ConfigMaps or Secrets</li><li>Using DB as a simple job queue, where inserting data automatically creates Job resources</li><li>Deploying per-node workloads in edge computing based on device lists in a central DB</li><li>Auto-generating individual lab environments in learning platforms based on student registration</li></ul><p>Nothing revolutionary, but things I&#39;d thought &quot;this would be nice to integrate with K8s&quot; while working.</p><p>The name &quot;Tenant&quot; no longer fit. This tool could link all kinds of entities, not just tenants.</p><p>So I chose the name &quot;Lynq,&quot; a variation of &quot;link,&quot; meaning connecting external data with Kubernetes.</p><h2 id="infrastructure-as-data-a-new-paradigm" tabindex="-1">Infrastructure as Data: A New Paradigm <a class="header-anchor" href="#infrastructure-as-data-a-new-paradigm" aria-label="Permalink to &quot;Infrastructure as Data: A New Paradigm&quot;">â€‹</a></h2><p>While developing Lynq, I realized I was using a different approach from traditional Infrastructure as Code (IaC).</p><p><strong>Infrastructure as Code</strong> defines infrastructure as code. Terraform, Pulumi, CDK are prime examples. But IaC has limitations:</p><ul><li>Hard to respond to dynamic requirements (modify code every time a new customer comes?)</li><li>Hard to reflect external system state in real-time</li><li>Inefficient for managing large-scale similar resources</li></ul><p>Lynq&#39;s approach is different. Define the &quot;structure&quot; of infrastructure in templates, but let data determine &quot;what&quot; to provision.</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span>IaC: Code â†’ Infrastructure</span></span>
<span class="line"><span>IaD: Data + Template â†’ Infrastructure</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>This way, only templates containing repetitive structures need Git version control. The actual repetitive data comes from a dynamically managed database (single source of truth).</p><p>I decided to call this approach <strong>Infrastructure as Data (IaD)</strong>, or from an operations perspective, <strong>RecordOps</strong>. Each database record becomes the unit of infrastructure operations.</p><p>(Someone might argue that DB schemas and records can also be managed as code, so this is just a subset or variation of IaC. That&#39;s a fair point, and I&#39;m still thinking about it.)</p><h2 id="a-conversation-with-michael-dehaan" tabindex="-1">A Conversation with Michael DeHaan <a class="header-anchor" href="#a-conversation-with-michael-dehaan" aria-label="Permalink to &quot;A Conversation with Michael DeHaan&quot;">â€‹</a></h2><p>While organizing the Infrastructure as Data concept, I thought of Michael DeHaan, creator of Ansible. I remembered his 2013 writing about modeling infrastructure as &quot;text-based, middle-ground, data-driven policy,&quot; so I sent him an email asking for his thoughts on RecordOps.</p><p>He replied, but it wasn&#39;t what I expected. He&#39;d been away from this space for almost 10 years and was skeptical about the modern infrastructure ecosystem as a whole.</p><blockquote><p>&quot;YAML becoming a monster is true. There&#39;s hardly anything checking it, and it&#39;s hard to remember different YAML dialects across tools.&quot;</p></blockquote><blockquote><p>&quot;Most developers these days spend their time on deployment and editing YAML. Almost all of them would rather be coding, but they don&#39;t seem to realize the trap they&#39;ve walked into.&quot;</p></blockquote><blockquote><p>&quot;Early 2000s 3-tier architecture was fine. ELBs, load balancers, a caching layer was enough... now there are too many moving parts.&quot;</p></blockquote><p>Then he asked a sharp question: <strong>&quot;Is this just adding more complexity to an already complicated ecosystem?&quot;</strong></p><p>Honestly, I&#39;d thought about this too, but I&#39;d been too caught up in my work to properly reflect on it. He said complexity itself has become an &quot;economy.&quot; Complexity allows selling &quot;solutions&quot; to that complexity. Places that need maybe 2 IT people have whole teams just running cloud ops, and it&#39;s still down a lot.</p><p>I agree that Kubernetes is overkill for most companies. But Kubernetes also enables managing large-scale, self-healing infrastructure with minimal staff. At least in my case. Just 2 people have been running over 1,000 containers for more than 5 years, rarely having our sleep interrupted. Without it, I wouldn&#39;t have even thought about providing 200+ tenants independently.</p><p>Through the conversation, Lynq&#39;s goal became clear. Help manage large-scale repetitive infrastructure with minimal complexity. Simpler than before, if possible. YAML being terrible is undeniable, but everyone in the Kubernetes ecosystem is using it somehow anyway.</p><h2 id="baking-in-operational-experience" tabindex="-1">Baking in Operational Experience <a class="header-anchor" href="#baking-in-operational-experience" aria-label="Permalink to &quot;Baking in Operational Experience&quot;">â€‹</a></h2><p>I baked insights from operating Tenant Operator into Lynq.</p><p>Data-driven sync creates various situations. When you need to manually modify already-synced resources. When you need to force sync. When resources created once shouldn&#39;t be recreated. Engineers needed to control the full lifecycle of resources to their liking. Monitoring, logging, events. Basic features, but tricky to implement systematically.</p><p>The most recent feature I built was <a href="/blog/maxskew-implementation-lessons.html">maxSkew</a>. It prevents cluster meltdown when a single template change gets applied to hundreds of already-provisioned tenants all at once.</p>`,51)),a(r),e[2]||(e[2]=o('<p>Building these safety features one by one brought it to production-ready level.</p><h2 id="lynq-s-vision" tabindex="-1">Lynq&#39;s Vision <a class="header-anchor" href="#lynq-s-vision" aria-label="Permalink to &quot;Lynq&#39;s Vision&quot;">â€‹</a></h2><p>Lynq 1.x focused on using MySQL as a data source. There&#39;s plenty of room to expand.</p><h3 id="short-term-goals-v1-x-v2-0" tabindex="-1">Short-term Goals (v1.x ~ v2.0) <a class="header-anchor" href="#short-term-goals-v1-x-v2-0" aria-label="Permalink to &quot;Short-term Goals (v1.x ~ v2.0)&quot;">â€‹</a></h3><ul><li><strong>Multiple data source support</strong>: PostgreSQL, MongoDB, REST API, GraphQL</li><li><strong>Advanced rollout strategies</strong>: Canary, Blue-Green deployment support</li><li><strong>Enhanced observability</strong>: Detailed metrics and tracing</li></ul><h3 id="long-term-vision" tabindex="-1">Long-term Vision <a class="header-anchor" href="#long-term-vision" aria-label="Permalink to &quot;Long-term Vision&quot;">â€‹</a></h3><ul><li><strong>Cross-cluster sync</strong>: Consistent provisioning across multiple Kubernetes clusters</li><li><strong>Bidirectional sync</strong>: Reflect Kubernetes state back to external systems</li></ul><p>Ultimately, I want to simplify infrastructure deployment and operations that have become overly complex. So people can say &quot;With Lynq, I don&#39;t worry about deployment&quot; or &quot;Lynq handles zero-downtime automatically.&quot;</p><h2 id="closing" tabindex="-1">Closing <a class="header-anchor" href="#closing" aria-label="Permalink to &quot;Closing&quot;">â€‹</a></h2><p>Lynq started to solve my own problem. While building it, I found the scope of application was wider than expected, so I decided to share it.</p><p>HR systems, CRM, project management tools, IoT platforms... these systems have data that can be connected to infrastructure. Automating that connection is what Lynq does.</p><p>If you&#39;re facing similar problems, give <a href="https://github.com/k8s-lynq/lynq" target="_blank" rel="noreferrer">Lynq</a> a try. If you have feedback or ideas, let&#39;s talk on GitHub Issues or Discussions.</p><hr><p><em>Lynq is an open source project. Check out the code and contribute on <a href="https://github.com/k8s-lynq/lynq" target="_blank" rel="noreferrer">GitHub</a>.</em></p>',14)),a(i)])}const w=l(d,[["render",h]]);export{v as __pageData,w as default};
